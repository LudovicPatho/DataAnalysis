# Machine Learning techniques
- Preprocessing (missing values): see [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb), [1984 US Congres votes](1984%20US%20Congres%20votes/Supervised%20Learning%20with%20scikit-learn.ipynb)
- Preprocessing (centering & scaling, standardization method): see [Wine quality](Wine/Wine.ipynb)
- Pipelines with scikit-learn: see [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb), [1984 US Congres votes](1984%20US%20Congres%20votes/Supervised%20Learning%20with%20scikit-learn.ipynb), [Wine quality](Wine/Wine.ipynb)
- K-NN classifier with scikit-learn, supervised learning: see [MNIST digits recognition](MNIST%20digits%20recognition/K-NN%20classifier%20with%20scikit-learn%20(supervised%20learning).ipynb), [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb)
- Regression with scikit-learn, supervised learning: see [Boston housing](Boston%20housing/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb), [Gapminder I](Gapminder/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb)
- Lasso (L1) & Ridge (L2) regularized regression with scikit-learn, supervised learning: see [Boston housing](Boston%20housing/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb), [Gapminder I](Gapminder/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb)
- Ridge (L2) regularized regression with scikit-learn, supervised learning: see [Boston housing](Boston%20housing/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb), [Gapminder I](Gapminder/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb), [Auto](Automobile/Data%20Preprocessing.ipynb)
- Regularized regression using ElasticNet (scikit-learn): see [Gapminder I](Gapminder/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb)
- Logistic regression with scikit-learn: see [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb)
- Regression with categorical features: see [Auto](Automobile/Data%20Preprocessing.ipynb), [Gapminder II](Gapminder/Regression%20with%20categorical%20features.ipynb)
- ROC curve & AUC in scikit-learn: see [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb)
- Hyperparameter tuning with GridSearchCV and RandomizedSearchCV (scikit-learn): see [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb), [Gapminder I](Gapminder/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb)
- Decision trees with scikit-learn: see [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb)
- SVM (Super Vector Machines) with scikit-learn: see [1984 US Congres votes](1984%20US%20Congres%20votes/Supervised%20Learning%20with%20scikit-learn.ipynb)
- Hyperparameter tuning for the SVM classifier: see [Wine quality](Wine/Wine.ipynb)

# Plotting techniques
- Heatmap with seaborn: see [Gapminder I](Gapminder/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb)
- Boxplot (pandas): see [Gapminder II](Gapminder/Regression%20with%20categorical%20features.ipynb)

# Statistics
- Basic EDA: see [Lego shapes analysis](Legos/Legos.ipynb) (Datacamp)
- Manipulating pandas dataframes: see [US firstnames trends](NamesAnalysis/NamesAnalysis.ipynb) (Datacamp)