# Preprocessing
- Missing values: see [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb), [1984 US Congres votes](1984%20US%20Congres%20votes/Supervised%20Learning%20with%20scikit-learn.ipynb), [School budget](School%20budget/School%20budget.ipynb)
- Centering & scaling, standardization method: see [Wine quality](Wine/Wine.ipynb)
- Sparse interactions: see [School budget](School%20budget/School%20budget.ipynb)
- Standard scaler: see [Wine](Wine/KMeans.ipynb)
- Normalizer: see [Stocks](Stocks/KMeans.ipynb)
- Pipelines with scikit-learn: see [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb), [1984 US Congres votes](1984%20US%20Congres%20votes/Supervised%20Learning%20with%20scikit-learn.ipynb), [Wine quality](Wine/Wine.ipynb), [School budget](School%20budget/School%20budget.ipynb)

# Machine Learning techniques
- K-NN classifier with scikit-learn, supervised learning: see [MNIST digits recognition](MNIST%20digits%20recognition/K-NN%20classifier%20with%20scikit-learn%20(supervised%20learning).ipynb), [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb)
- Regression with scikit-learn, supervised learning: see [Boston housing](Boston%20housing/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb), [Gapminder I](Gapminder/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb)
- Lasso (L1) & Ridge (L2) regularized regression with scikit-learn, supervised learning: see [Boston housing](Boston%20housing/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb), [Gapminder I](Gapminder/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb)
- Ridge (L2) regularized regression with scikit-learn, supervised learning: see [Boston housing](Boston%20housing/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb), [Gapminder I](Gapminder/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb), [Auto](Automobile/Data%20Preprocessing.ipynb)
- Regularized regression using ElasticNet (scikit-learn): see [Gapminder I](Gapminder/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb)
- Logistic regression with scikit-learn: see [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb), [School budget](School%20budget/School%20budget.ipynb)
- Regression with categorical features: see [Auto](Automobile/Data%20Preprocessing.ipynb), [Gapminder II](Gapminder/Regression%20with%20categorical%20features.ipynb)
- ROC curve & AUC in scikit-learn: see [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb)
- Hyperparameter tuning with GridSearchCV and RandomizedSearchCV (scikit-learn): see [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb), [Gapminder I](Gapminder/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb)
- Decision trees with scikit-learn: see [Pima diabetes](PIMA%20Indians/K-NN%20classifier%20diabetes.ipynb)
- SVM (Super Vector Machines) with scikit-learn: see [1984 US Congres votes](1984%20US%20Congres%20votes/Supervised%20Learning%20with%20scikit-learn.ipynb)
- Hyperparameter tuning for the SVM classifier: see [Wine quality](Wine/Wine.ipynb)
- NLP techniques (CountVectorizer, HashingVectorizer): see [School budget](School%20budget/School%20budget.ipynb)
- Random Forest classifier: see [School budget](School%20budget/School%20budget.ipynb)
- KMeans clustering, cross-tabulation (unsupervized learning): see [Grains](Grains/KMeans.ipynb), [Fish](Fish/KMeans.ipynb), [Stocks](Stocks/KMeans.ipynb)
- Hierarchical clustering (unsupervized learning): see [Stocks](Stocks/KMeans.ipynb)
- Dimension reduction using PCA: see [Grains](Grains/KMeans.ipynb), [Fish](Fish/KMeans.ipynb)
- Dimension reduction using TruncateSVD: see [Wiki](Wikipedia%20articles/Analysis.ipynb)
- Dimension reduction using NMF: see [Wiki](Wikipedia%20articles/Analysis.ipynb)

# Plotting techniques
- Heatmap with seaborn: see [Gapminder I](Gapminder/Regression%20with%20scikit-learn%20(supervised%20learning).ipynb)
- Boxplot (pandas): see [Gapminder II](Gapminder/Regression%20with%20categorical%20features.ipynb)
- t-SNE visualization (unsupervized learning): see [Grains](Grains/KMeans.ipynb), [Stocks](Stocks/KMeans.ipynb)

# Statistics
- Basic EDA: see [Lego shapes analysis](Legos/Legos.ipynb) (Datacamp)
- Manipulating pandas dataframes: see [US firstnames trends](NamesAnalysis/NamesAnalysis.ipynb) (Datacamp)

# Kaggle
- [Titanic](Titanic/Titanic.ipynb)